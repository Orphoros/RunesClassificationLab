{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Feature extraction\n",
    "\n",
    "In this iteration we use manual image classification. For this, we only extract a few features where we can easily categories each image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adding the libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage as si\n",
    "from skimage import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load in all images\n",
    "\n",
    "All images are loaded in into an array as a tuple of (image, label). This way we know what image we are dealing with. We also lowercase all the labels as \"Tyr\" is in uppercase, while everything else is in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1472\n",
      "All labels: {'sun', 'wealth', 'bow', 'ash', 'elk-sedge', 'oak', 'need', 'spear', 'tyr', 'joy', 'gift', 'serpent'}\n"
     ]
    }
   ],
   "source": [
    "directory = \"../dataset-images/\" # Path to the dataset\n",
    "images = [] # List of images\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file is an image\n",
    "    if filename.endswith(\".png\"):\n",
    "        label = filename.split(\"_\")[0].lower() # Get the label\n",
    "        # Label and load the image\n",
    "        img = io.imread(os.path.join(directory, filename))\n",
    "        images.append((img, label))\n",
    "\n",
    "# Print the number of images\n",
    "print(\"Number of images: \" + str(len(images)))\n",
    "print(\"All labels: \" + str(set([label for _, label in images])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature extraction\n",
    "\n",
    "We first have to check if the image has 2 channels, as at least one image (based on runtime error) in the dataset had only 2 channels.\n",
    "\n",
    "Then, we process the image with the following steps:\n",
    "\n",
    "1. **Convert to grayscale:** we do not care about the color of the image, so we convert it to grayscale (in case the image is not already grayscale)\n",
    "2. **Remove alpha channel:** we do not care about the alpha channel, it is just extra data, so we remove it to save on processing power\n",
    "3. **Binary erosion:** we erode the image to remove noise and make the image more clear\n",
    "\n",
    "We want to make sure that we only have black pixels in our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = [] # List of processed images\n",
    "\n",
    "for img, label in images:\n",
    "    # if the image is not RGB, convert it\n",
    "    if len(img.shape) == 2:\n",
    "        img = si.color.gray2rgb(img)\n",
    "    # remove the alpha channel\n",
    "    img = img[:, :, :3]\n",
    "    # binary color scale\n",
    "    img = si.color.rgb2gray(img)\n",
    "    threshold_value = si.filters.threshold_otsu(img)\n",
    "    img = img > threshold_value\n",
    "    # Apply erosion\n",
    "    img = si.morphology.binary_erosion(img, si.morphology.square(3))\n",
    "    # Label the image\n",
    "    img = si.measure.label(img)\n",
    "\n",
    "    processed.append((img, label))\n",
    "\n",
    "# We do this only to print an example processed image\n",
    "for img, label in processed:\n",
    "    if label == 'spear':\n",
    "        print(f'Label: {label}')\n",
    "        io.imshow(img)\n",
    "        io.show()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Measure the labeled image properties\n",
    "\n",
    "Finally, we extract various features from each image using the regionprops of scikit-image. We extract the `number of regions` and `black pixel count` of each image. We only extract these two features since we are doing manual categorization and we want few, but precise features.\n",
    "\n",
    "We then save the features in a csv file. The output of this notebook is a csv file with the following columns: `label, black_pixels, regions`. It is saved in `dataset-numpy/1.0 - features.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [] # List of features\n",
    "\n",
    "for labeled_img, label in processed:\n",
    "    data = si.measure.regionprops(labeled_img)\n",
    "    # Extract the num of black pixels from the labeled image\n",
    "    total_pixels = labeled_img.size\n",
    "    foreground_pixels = np.sum(labeled_img > 0)\n",
    "    black_pixels = total_pixels - foreground_pixels\n",
    "    # Get num of holes\n",
    "    regions = len(data)\n",
    "    features.append((label, black_pixels, regions))\n",
    "\n",
    "# make csv file\n",
    "directory = \"../dataset-numpy/\" \n",
    "path = os.path.join(directory, '1.0 - features.csv')\n",
    "with open(path, 'w', newline='') as f:\n",
    "    # Print csv header\n",
    "    print(\"label,black_pixels,regions\", file=f)\n",
    "    # Print csv rows\n",
    "    for label, pixels, regions in features:\n",
    "        print(label + \",\" + str(pixels) + \",\" + str(regions), file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
